"""æ‰¹é‡å¤„ç†å‘½ä»¤æ¨¡å—

æä¾›åŸºäºæ‰¹é‡å¤„ç†å™¨çš„å‘½ä»¤è¡Œæ¥å£ï¼Œæ”¯æŒï¼š
- æ‰¹é‡åˆ†æé”™è¯¯
- ç”Ÿæˆåˆ†ç»„æŠ¥å‘Š
- äº¤äº’å¼ä¿®å¤æ“ä½œ
- ç»¼åˆæ‰¹é‡æŠ¥å‘Šç”Ÿæˆ
"""

import sys
from datetime import datetime

from ..core.batch_processor import BatchErrorProcessor, ErrorCategory
from ..core.batch_reporter import BatchReportGenerator, BatchReportConfig
from ..utils.scanner import get_latest_file


def _print_header(message: str):
    """æ‰“å°å¸¦è¾¹æ¡†çš„æ ‡é¢˜."""
    print("\n" + "=" * 80)
    print(message)
    print("=" * 80 + "\n")


def _print_section(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜."""
    print(f"\n{'-' * 60}")
    print(f"  {title}")
    print(f"{'-' * 60}")


def cmd_batch_analyze(args) -> int:
    """æ‰¹é‡åˆ†æå‘½ä»¤ï¼šåˆ†æé”™è¯¯æ–‡ä»¶å¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š

    Usage:
        basedpyright batch-analyze [--input ERRORS_FILE] [--output OUTPUT_DIR]

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡

    Returns:
        é€€å‡ºç ï¼ˆ0=æˆåŠŸï¼Œ1=å¤±è´¥ï¼‰
    """
    _print_header("Step 4: æ‰¹é‡åˆ†æé”™è¯¯æ•°æ®")

    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    input_dir = args.input
    errors_file = args.errors_file

    if not errors_file:
        print(f"æœªæŒ‡å®šé”™è¯¯æ–‡ä»¶ï¼Œåœ¨ {input_dir} ä¸­æŸ¥æ‰¾æœ€æ–°çš„é”™è¯¯æ–‡ä»¶...")
        errors_file = get_latest_file(input_dir, "basedpyright_errors_only_*.json")
        if errors_file:
            print(f"  æ‰¾åˆ°: {errors_file.name}")
        else:
            print("  é”™è¯¯: æœªæ‰¾åˆ°é”™è¯¯æ–‡ä»¶")
            return 1
    else:
        print(f"ä½¿ç”¨é”™è¯¯æ–‡ä»¶: {errors_file}")

    if not errors_file.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {errors_file}")
        return 1

    print()

    try:
        # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨
        processor = BatchErrorProcessor(errors_file)

        # åŠ è½½é”™è¯¯æ•°æ®
        if not processor.load_errors():
            print("é”™è¯¯: æ— æ³•åŠ è½½é”™è¯¯æ–‡ä»¶")
            return 1

        print(f"å·²åŠ è½½ {len(processor.raw_errors)} ä¸ªåŸå§‹é”™è¯¯")

        # æ‰§è¡Œåˆ†æ
        stats = processor.analyze()

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        _print_section("åˆ†æç»Ÿè®¡")
        print(f"åŸå§‹é”™è¯¯æ•°é‡: {stats.total_errors}")
        print(f"å»é‡åé”™è¯¯æ•°é‡: {stats.unique_errors}")
        print(f"å¤„ç†è€—æ—¶: {stats.processing_time:.2f}ç§’")
        print(f"é”™è¯¯åˆ†ç»„æ•°é‡: {stats.groups_count}")
        print(f"å¯è‡ªåŠ¨ä¿®å¤é”™è¯¯: {stats.auto_fixable_count}")

        _print_section("é”™è¯¯åˆ†ç±»ç»Ÿè®¡")
        for category, count in stats.by_category.items():
            percentage = (count / stats.unique_errors * 100) if stats.unique_errors > 0 else 0
            print(f"  {category}: {count} ({percentage:.1f}%)")

        _print_section("ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡")
        for severity, count in stats.by_severity.items():
            percentage = (count / stats.unique_errors * 100) if stats.unique_errors > 0 else 0
            print(f"  {severity}: {count} ({percentage:.1f}%)")

        _print_section("Top 10 é”™è¯¯æ–‡ä»¶")
        for file_path, count in list(stats.by_file.items())[:10]:
            print(f"  {file_path}: {count} ä¸ªé”™è¯¯")

        # æ˜¾ç¤ºé”™è¯¯åˆ†ç»„
        if processor.error_groups:
            _print_section("é”™è¯¯åˆ†ç»„")
            for i, group in enumerate(processor.error_groups[:5], 1):
                print(f"\n  åˆ†ç»„ {i}: {group.pattern}")
                print(f"    é”™è¯¯æ•°é‡: {len(group.errors)}")
                print(f"    å¯è‡ªåŠ¨ä¿®å¤: {'æ˜¯' if group.auto_fixable else 'å¦'}")
                if group.common_fix:
                    print(f"    é€šç”¨å»ºè®®: {group.common_fix}")

                # æ˜¾ç¤ºå‰å‡ ä¸ªé”™è¯¯ç¤ºä¾‹
                for j, error in enumerate(group.errors[:3], 1):
                    print(f"      {j}. {error.file}:{error.line} - {error.message[:80]}...")
                if len(group.errors) > 3:
                    print(f"      ... è¿˜æœ‰ {len(group.errors) - 3} ä¸ªç±»ä¼¼é”™è¯¯")

        # å¯¼å‡ºè¯¦ç»†æŠ¥å‘Š
        output_dir = args.output
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = output_dir / f"batch_analysis_report_{timestamp}.json"

        if processor.export_analysis_report(report_file):
            print("\n[OK] åˆ†æå®Œæˆï¼")
            print(f"  è¯¦ç»†æŠ¥å‘Š: {report_file}")
        else:
            print("\nè­¦å‘Š: è¯¦ç»†æŠ¥å‘Šå¯¼å‡ºå¤±è´¥")
            return 1

        # æ˜¾ç¤ºå¯è‡ªåŠ¨ä¿®å¤çš„é”™è¯¯æ•°é‡
        auto_fixable = processor.get_auto_fixable_errors()
        if auto_fixable:
            print(f"\nå¯ç«‹å³è‡ªåŠ¨ä¿®å¤çš„é”™è¯¯: {len(auto_fixable)} ä¸ª")
            print("è¿è¡Œ 'basedpyright batch-fix' å¼€å§‹è‡ªåŠ¨ä¿®å¤")

        return 0

    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


def cmd_batch_fix(args) -> int:
    """æ‰¹é‡ä¿®å¤å‘½ä»¤ï¼šäº¤äº’å¼ä¿®å¤ç®€å•é”™è¯¯

    Usage:
        basedpyright batch-fix [--input ERRORS_FILE] [--auto] [--dry-run]

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡

    Returns:
        é€€å‡ºç ï¼ˆ0=æˆåŠŸï¼Œ1=å¤±è´¥ï¼‰
    """
    _print_header("Step 5: æ‰¹é‡ä¿®å¤é”™è¯¯")

    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    input_dir = args.input
    errors_file = args.errors_file

    if not errors_file:
        print(f"æœªæŒ‡å®šé”™è¯¯æ–‡ä»¶ï¼Œåœ¨ {input_dir} ä¸­æŸ¥æ‰¾æœ€æ–°çš„é”™è¯¯æ–‡ä»¶...")
        errors_file = get_latest_file(input_dir, "basedpyright_errors_only_*.json")
        if errors_file:
            print(f"  æ‰¾åˆ°: {errors_file.name}")
        else:
            print("  é”™è¯¯: æœªæ‰¾åˆ°é”™è¯¯æ–‡ä»¶")
            return 1

    print(f"ä½¿ç”¨é”™è¯¯æ–‡ä»¶: {errors_file}")

    try:
        # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨å¹¶åˆ†æ
        processor = BatchErrorProcessor(errors_file)
        if not processor.load_errors():
            print("é”™è¯¯: æ— æ³•åŠ è½½é”™è¯¯æ–‡ä»¶")
            return 1

        stats = processor.analyze()
        auto_fixable = processor.get_auto_fixable_errors()

        if not auto_fixable:
            print("\næ²¡æœ‰æ‰¾åˆ°å¯è‡ªåŠ¨ä¿®å¤çš„é”™è¯¯")
            return 0

        print(f"\næ‰¾åˆ° {len(auto_fixable)} ä¸ªå¯è‡ªåŠ¨ä¿®å¤çš„é”™è¯¯")

        if not args.auto:
            # äº¤äº’å¼ç¡®è®¤
            print("\nå°†è¦ä¿®å¤ä»¥ä¸‹é”™è¯¯ç±»å‹:")
            for category in ErrorCategory:
                errors = processor.get_errors_by_category(category)
                if errors and category == ErrorCategory.SIMPLE:
                    print(f"  {category.value}: {len(errors)} ä¸ªé”™è¯¯")

            try:
                response = input("\næ˜¯å¦ç»§ç»­ä¿®å¤? (y/N): ")
                if response.lower() not in ['y', 'yes']:
                    print("ä¿®å¤å·²å–æ¶ˆ")
                    return 0
            except (EOFError, KeyboardInterrupt):
                print("\nä¿®å¤å·²å–æ¶ˆï¼ˆæ— äº¤äº’ç¯å¢ƒæˆ–ç”¨æˆ·ä¸­æ–­ï¼‰")
                return 0

        if args.dry_run:
            print("\n[DRY RUN] å°†è¦ä¿®å¤çš„é”™è¯¯:")
            for i, error in enumerate(auto_fixable[:10], 1):
                print(f"  {i}. {error.file}:{error.line}")
                print(f"     é”™è¯¯: {error.message}")
                print(f"     å»ºè®®: {error.fix_suggestion}")
                print(f"     ç½®ä¿¡åº¦: {error.confidence:.1%}")
                print()

            if len(auto_fixable) > 10:
                print(f"  ... è¿˜æœ‰ {len(auto_fixable) - 10} ä¸ªé”™è¯¯")
        else:
            # è¿™é‡Œåº”è¯¥é›†æˆå®é™…çš„ä¿®å¤é€»è¾‘
            # ç›®å‰åªæ˜¯æ¼”ç¤ºï¼Œå®é™…çš„ä¿®å¤éœ€è¦ç»“åˆå…·ä½“çš„ä»£ç ä¿®æ”¹
            print("\n[æ³¨æ„] è‡ªåŠ¨ä¿®å¤åŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥å®ç°")
            print("å½“å‰ä»…æ”¯æŒé”™è¯¯åˆ†æå’Œå»ºè®®ç”Ÿæˆ")

        return 0

    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


def cmd_batch_report(args) -> int:
    """æ‰¹é‡æŠ¥å‘Šå‘½ä»¤ï¼šç”ŸæˆMarkdownæ ¼å¼çš„æ‰¹é‡å¤„ç†æŠ¥å‘Š

    Usage:
        basedpyright batch-report [--input ERRORS_FILE] [--output OUTPUT_DIR]

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡

    Returns:
        é€€å‡ºç ï¼ˆ0=æˆåŠŸï¼Œ1=å¤±è´¥ï¼‰
    """
    _print_header("Step 6: ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š")

    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    input_dir = args.input
    errors_file = args.errors_file

    if not errors_file:
        errors_file = get_latest_file(input_dir, "basedpyright_errors_only_*.json")
        if errors_file:
            print(f"ä½¿ç”¨é”™è¯¯æ–‡ä»¶: {errors_file.name}")
        else:
            print("é”™è¯¯: æœªæ‰¾åˆ°é”™è¯¯æ–‡ä»¶")
            return 1

    try:
        # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨å¹¶åˆ†æ
        processor = BatchErrorProcessor(errors_file)
        if not processor.load_errors():
            print("é”™è¯¯: æ— æ³•åŠ è½½é”™è¯¯æ–‡ä»¶")
            return 1

        stats = processor.analyze()

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        output_dir = args.output
        output_dir.mkdir(parents=True, exist_ok=True)

        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = output_dir / f"batch_processing_report_{timestamp}.md"

        with open(report_file, 'w', encoding='utf-8') as f:
            # æŠ¥å‘Šå¤´éƒ¨
            f.write("# BasedPyright æ‰¹é‡å¤„ç†æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**æºæ–‡ä»¶**: `{errors_file.name}`\n\n")

            # æ‰§è¡Œæ‘˜è¦
            f.write("## æ‰§è¡Œæ‘˜è¦\n\n")
            f.write(f"- **åŸå§‹é”™è¯¯æ•°é‡**: {stats.total_errors}\n")
            f.write(f"- **å»é‡åé”™è¯¯æ•°é‡**: {stats.unique_errors}\n")
            f.write(f"- **å¤„ç†è€—æ—¶**: {stats.processing_time:.2f}ç§’\n")
            f.write(f"- **é”™è¯¯åˆ†ç»„æ•°é‡**: {stats.groups_count}\n")
            f.write(f"- **å¯è‡ªåŠ¨ä¿®å¤é”™è¯¯**: {stats.auto_fixable_count}\n\n")

            # é”™è¯¯åˆ†ç±»ç»Ÿè®¡
            f.write("## é”™è¯¯åˆ†ç±»ç»Ÿè®¡\n\n")
            f.write("| åˆ†ç±» | æ•°é‡ | å æ¯” |\n")
            f.write("|------|------|------|\n")
            for category, count in stats.by_category.items():
                percentage = (count / stats.unique_errors * 100) if stats.unique_errors > 0 else 0
                f.write(f"| {category} | {count} | {percentage:.1f}% |\n")
            f.write("\n")

            # ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
            f.write("## ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡\n\n")
            f.write("| ä¸¥é‡ç¨‹åº¦ | æ•°é‡ | å æ¯” |\n")
            f.write("|----------|------|------|\n")
            for severity, count in stats.by_severity.items():
                percentage = (count / stats.unique_errors * 100) if stats.unique_errors > 0 else 0
                f.write(f"| {severity} | {count} | {percentage:.1f}% |\n")
            f.write("\n")

            # Topé”™è¯¯æ–‡ä»¶
            f.write("## Top 10 é”™è¯¯æ–‡ä»¶\n\n")
            f.write("| æ–‡ä»¶è·¯å¾„ | é”™è¯¯æ•°é‡ |\n")
            f.write("|----------|----------|\n")
            for file_path, count in list(stats.by_file.items())[:10]:
                f.write(f"| `{file_path}` | {count} |\n")
            f.write("\n")

            # é”™è¯¯åˆ†ç»„è¯¦æƒ…
            if processor.error_groups:
                f.write("## é”™è¯¯åˆ†ç»„åˆ†æ\n\n")
                for i, group in enumerate(processor.error_groups, 1):
                    f.write(f"### åˆ†ç»„ {i}: {group.pattern}\n\n")
                    f.write(f"- **é”™è¯¯æ•°é‡**: {len(group.errors)}\n")
                    f.write(f"- **å¯è‡ªåŠ¨ä¿®å¤**: {'æ˜¯' if group.auto_fixable else 'å¦'}\n")
                    if group.common_fix:
                        f.write(f"- **é€šç”¨å»ºè®®**: {group.common_fix}\n")
                    f.write("\n")

                    f.write("#### é”™è¯¯è¯¦æƒ…\n\n")
                    for j, error in enumerate(group.errors, 1):
                        f.write(f"{j}. **{error.file}:{error.line}**\n")
                        f.write(f"   - **é”™è¯¯**: {error.message}\n")
                        f.write(f"   - **è§„åˆ™**: {error.rule}\n")
                        f.write(f"   - **ä¸¥é‡ç¨‹åº¦**: {error.severity_level.value}\n")
                        if error.fix_suggestion:
                            f.write(f"   - **ä¿®å¤å»ºè®®**: {error.fix_suggestion}\n")
                        f.write(f"   - **ç½®ä¿¡åº¦**: {error.confidence:.1%}\n\n")
                    f.write("---\n\n")

            # å¯è‡ªåŠ¨ä¿®å¤çš„é”™è¯¯
            auto_fixable = processor.get_auto_fixable_errors()
            if auto_fixable:
                f.write("## å¯è‡ªåŠ¨ä¿®å¤çš„é”™è¯¯\n\n")
                f.write(f"å…±æ‰¾åˆ° {len(auto_fixable)} ä¸ªå¯è‡ªåŠ¨ä¿®å¤çš„é”™è¯¯:\n\n")
                for i, error in enumerate(auto_fixable, 1):
                    f.write(f"{i}. **{error.file}:{error.line}**\n")
                    f.write(f"   - **é”™è¯¯**: {error.message}\n")
                    f.write(f"   - **ä¿®å¤å»ºè®®**: {error.fix_suggestion}\n")
                    f.write(f"   - **ç½®ä¿¡åº¦**: {error.confidence:.1%}\n\n")

            # å»ºè®®å’Œåç»­æ­¥éª¤
            f.write("## å»ºè®®å’Œåç»­æ­¥éª¤\n\n")
            if stats.auto_fixable_count > 0:
                f.write("1. **ç«‹å³è‡ªåŠ¨ä¿®å¤**: è¿è¡Œ `basedpyright batch-fix` ä¿®å¤ç®€å•é”™è¯¯\n")
            if stats.groups_count > 0:
                f.write("2. **æ‰¹é‡å¤„ç†**: ä¼˜å…ˆå¤„ç†é”™è¯¯åˆ†ç»„ä¸­çš„ç±»ä¼¼é—®é¢˜\n")
            if stats.by_severity.get('critical', 0) > 0 or stats.by_severity.get('high', 0) > 0:
                f.write("3. **ä¼˜å…ˆå¤„ç†**: é¦–å…ˆè§£å†³é«˜ä¸¥é‡ç¨‹åº¦å’Œå…³é”®é”™è¯¯\n")
            f.write("4. **æŒç»­ç›‘æ§**: å®šæœŸè¿è¡Œæ£€æŸ¥ä»¥ä¿æŒä»£ç è´¨é‡\n")

        print("\n[OK] æ‰¹é‡å¤„ç†æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        print(f"  æŠ¥å‘Šæ–‡ä»¶: {report_file}")

        return 0

    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


def cmd_batch_report_enhanced(args) -> int:
    """å¢å¼ºæ‰¹é‡æŠ¥å‘Šå‘½ä»¤ï¼šä½¿ç”¨æ–°çš„æ‰¹é‡æŠ¥å‘Šç”Ÿæˆå™¨åˆ›å»ºç»¼åˆæŠ¥å‘Š

    Usage:
        basedpyright batch-report-enhanced [--input ERRORS_FILE] [--output OUTPUT_DIR] [--config CONFIG]

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡

    Returns:
        é€€å‡ºç ï¼ˆ0=æˆåŠŸï¼Œ1=å¤±è´¥ï¼‰
    """
    _print_header("Step 6+: ç”Ÿæˆå¢å¼ºæ‰¹é‡å¤„ç†æŠ¥å‘Š")

    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    input_dir = args.input
    errors_file = args.errors_file

    # é…ç½®æ‰¹é‡æŠ¥å‘Šç”Ÿæˆå™¨
    config = BatchReportConfig()
    if hasattr(args, 'include_trends') and not args.include_trends:
        config.include_trends = False
    if hasattr(args, 'include_file_comparison') and not args.include_file_comparison:
        config.include_file_comparison = False
    if hasattr(args, 'max_error_details'):
        config.max_error_details = args.max_error_details

    try:
        # åˆ›å»ºæ‰¹é‡æŠ¥å‘Šç”Ÿæˆå™¨
        report_generator = BatchReportGenerator(config)

        if errors_file:
            # å•æ–‡ä»¶æ¨¡å¼
            print(f"ä½¿ç”¨é”™è¯¯æ–‡ä»¶: {errors_file}")
            if not errors_file.exists():
                print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {errors_file}")
                return 1

            processor = BatchErrorProcessor(errors_file)
            if processor.load_errors():
                processor.analyze()
                report_generator.add_processor(processor)
                print(f"å·²åŠ è½½ {len(processor.processed_errors)} ä¸ªå¤„ç†åçš„é”™è¯¯")
            else:
                print("é”™è¯¯: æ— æ³•åŠ è½½é”™è¯¯æ–‡ä»¶")
                return 1
        else:
            # å¤šæ–‡ä»¶æ¨¡å¼ - è‡ªåŠ¨å‘ç°å¹¶åŠ è½½æ‰€æœ‰é”™è¯¯æ–‡ä»¶
            print(f"åœ¨ {input_dir} ä¸­æŸ¥æ‰¾æ‰€æœ‰é”™è¯¯æ–‡ä»¶...")
            error_files = list(input_dir.glob("basedpyright_errors_only_*.json"))

            if not error_files:
                print("é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•é”™è¯¯æ–‡ä»¶")
                return 1

            print(f"æ‰¾åˆ° {len(error_files)} ä¸ªé”™è¯¯æ–‡ä»¶")
            if not report_generator.load_from_files(error_files):
                print("è­¦å‘Š: éƒ¨åˆ†æ–‡ä»¶åŠ è½½å¤±è´¥")

        # åŠ è½½å†å²æ•°æ®ç”¨äºè¶‹åŠ¿åˆ†æ
        if config.include_trends:
            print("åŠ è½½å†å²æ•°æ®ç”¨äºè¶‹åŠ¿åˆ†æ...")
            report_generator.load_historical_data(input_dir, days=30)

        # ç”ŸæˆæŠ¥å‘Š
        output_dir = args.output
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        comprehensive_report = output_dir / f"batch_comprehensive_report_{timestamp}.md"
        report_generator.generate_comprehensive_markdown(comprehensive_report)

        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        summary_report = output_dir / f"batch_summary_report_{timestamp}.md"
        report_generator.generate_summary_report(summary_report)

        print("\n[OK] å¢å¼ºæ‰¹é‡æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        print(f"  ç»¼åˆæŠ¥å‘Š: {comprehensive_report}")
        print(f"  æ‘˜è¦æŠ¥å‘Š: {summary_report}")

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if report_generator.processors:
            total_errors = sum(p.stats.total_errors for p in report_generator.processors if p.stats)
            total_unique = sum(p.stats.unique_errors for p in report_generator.processors if p.stats)
            total_auto_fixable = sum(p.stats.auto_fixable_count for p in report_generator.processors if p.stats)

            print("\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"  æ€»é”™è¯¯æ•°: {total_errors}")
            print(f"  å»é‡é”™è¯¯: {total_unique}")
            print(f"  å¯è‡ªåŠ¨ä¿®å¤: {total_auto_fixable} ({total_auto_fixable/total_unique*100:.1f}%)")

            if report_generator.trend_data:
                print(f"  è¶‹åŠ¿æ•°æ®ç‚¹: {len(report_generator.trend_data)}")

        return 0

    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1